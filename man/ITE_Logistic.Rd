% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LF_logistic.R
\name{ITE_Logistic}
\alias{ITE_Logistic}
\title{Inference for diference of case probabilities in the high dimensional logistic regression}
\usage{
ITE_Logistic(
  X1,
  y1,
  X2,
  y2,
  loading,
  weight = NULL,
  intercept = TRUE,
  init.Lasso1 = NULL,
  init.Lasso2 = NULL,
  lambda1 = NULL,
  lambda2 = NULL,
  mu1 = NULL,
  mu2 = NULL,
  step1 = NULL,
  step2 = NULL,
  resol = 1.5,
  maxiter = 10
)
}
\arguments{
\item{X1}{First design matrix, of dimension \eqn{n_1} x \eqn{p}}

\item{y1}{First outcome vector, of length \eqn{n_1}}

\item{X2}{Second design matrix, of dimension \eqn{n_2} x \eqn{p}}

\item{y2}{Second outcome vector, of length \eqn{n_2}}

\item{loading}{Loading, of length \eqn{p}}

\item{weight}{The weight vector, of length \eqn{n}, used in correcting the plug-in estimators, uses the inverse Hessian weight if set to \code{NULL} (default = \code{NULL})}

\item{intercept}{Should intercept(s) be fitted (default = \code{TRUE})}

\item{init.Lasso1}{Initial LASSO estimator of the regression vector \eqn{\beta_1} (default = \code{NULL})}

\item{init.Lasso2}{Initial LASSO estimator of the regression vector \eqn{\beta_2} (default = \code{NULL})}

\item{lambda1}{The tuning parameter in the construction of LASSO estimator of the regression vector \eqn{\beta_1} (default = \code{NULL})}

\item{lambda2}{The tuning parameter in the construction of LASSO estimator of the regression vector \eqn{\beta_2} (default = \code{NULL})}

\item{mu1}{The dual tuning parameter used in the construction of the first \eqn{(k=1)} projection direction (default = \code{NULL})}

\item{mu2}{The dual tuning parameter used in the construction of the second \eqn{(k=2)} projection direction (default = \code{NULL})}

\item{step1}{Number of steps (< \code{maxiter}) to obtain the smallest \code{mu}
such that the dual optimization problem for constructing the first \eqn{(k=1)} projection direction converges (default = \code{NULL})}

\item{step2}{Number of steps (< \code{maxiter}) to obtain the smallest \code{mu}
such that the dual optimization problem for constructing the second \eqn{(k=2)} projection direction converges (default = \code{NULL})}

\item{resol}{Resolution or the factor by which \code{mu} is increased/decreased to obtain the smallest \code{mu}
such that the dual optimization problem for constructing the projection direction converges (default = 1.5)}

\item{maxiter}{Maximum number of steps along which \code{mu} is increased/decreased to obtain the smallest \code{mu}
such that the dual optimization problem for constructing the projection direction converges (default = 10)}
}
\value{
\item{prop.est}{The bias-corrected estimator for the difference of case probabilities}
\item{se}{The standard error of the bias-corrected estimator}
\item{proj1}{The first \eqn{(k=1)} projection direction, of length \eqn{p}}
\item{proj2}{The second \eqn{(k=2)} projection direction, of length \eqn{p}}
\item{plug.in1}{The plug-in LASSO estimator for the first \eqn{(k=1)} linear functional}
\item{plug.in2}{The plug-in LASSO estimator for the second \eqn{(k=2)} linear functional}
}
\description{
Computes the bias corrected estimator of \eqn{(\frac{e^{\code{loading}^{\top}\beta_1}}{1+e^{\code{loading}^{\top}\beta_1}})-\frac{e^{\code{loading}^{\top}\beta_2}}{1+e^{\code{loading}^{\top}\beta_2}})} for the high dimensional logistic regression \eqn{Y_k|X_k \sim } Bernoulli\eqn{(\frac{e^{X_k\beta_k}}{1+e^{X_k\beta_k}}),  k=1,2} and the corresponding standard error.
}
\examples{
A1gen <- function(rho,p){
A1=matrix(0,p,p)
for(i in 1:p){
  for(j in 1:p){
    A1[i,j]<-rho^(abs(i-j))
  }
}
A1
}
n1 = 100
n2 = 200
p = 400
mu <- rep(0,p)
rho = 0.5
Cov <- (A1gen(rho,p))/2
Cov2<-matrix(NA,nrow=p,ncol=p)
for(i in 1:p){
  for(j in 1:p){
    Cov2[i,j]<-0.5^(1+abs(i-j))
  }
}
beta1 <- rep(0,p)
beta1[1:10] <- c(1:10)/5
beta2 <- rep(0,p)
beta2[1:5] <- c(1:5)/10
X1 <- MASS::mvrnorm(n1,mu,Cov)
X2 <- MASS::mvrnorm(n2,mu,Cov)
exp_val1 <- X1\%*\%beta1
exp_val2 <- X2\%*\%beta2
prob1 <- exp(exp_val1)/(1+exp(exp_val1))
prob2 <- exp(exp_val2)/(1+exp(exp_val2))
y1 <- rbinom(n1,1,prob1)
y2 <- rbinom(n2,1,prob2)
loading <- MASS::mvrnorm(1,mu,Cov2)
Est <- ITE_Logistic(X1 = X1, y1 = y1, X2 = X2, y2 = y2,loading = loading, intercept = TRUE)
}
